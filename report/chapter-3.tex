We have extended the pipeline with support for parameter learning. For this functionality, our program expects a file containing tunable probabilities and another file containing values for all probabilities (the ground truth). The ground truth is necessary for generation of interpretations. The amount of interpretations to be generated can be set as well. More information about this feature can be found in \texttt{README.MD}.

\section{Generated interpretations}
Four interpretations can be generated with the following command:
\begin{lstlisting}
python3 scripts/inference.py --problog_learn files/problog/cancer_learn.pl --problog_learn_truth files/problog/cancer.pl --learning_interpretations 4
\end{lstlisting}
Observations will be dropped with a probability of 30\% automatically and the resulting interpretations will be written to src/files/interpretations.txt.

Here is an example of generated interpretations with the command listed above:
\begin{lstlisting}
evidence(\+cancer).
evidence(\+xray("positive")).
evidence(\+dyspnoea).
evidence(\+pollution("high")).
evidence(\+smoker).
====================================================
evidence(smoker).
evidence(dyspnoea).
evidence(\+pollution("high")).
evidence(pollution("low")).
====================================================
evidence(xray("negative")).
evidence(\+dyspnoea).
evidence(\+pollution("high")).
evidence(\+smoker).
====================================================
evidence(smoker).
evidence(dyspnoea).
evidence(\+pollution("high")).
evidence(pollution("low")).
\end{lstlisting}

\section{Pipeline with interpretations}
The following table shows parameters that were learned for varying amounts of interpretations (m). The parameters for m = 10 were reached after 45 iterations. Our current implementation determines convergence is reached when all parameters change by less than 0.005. For m = 100, the program was terminated after 1.5 hours at 39 iterations, and for m = 1000, it was terminated after 1.5 hours at 3 iterations.

\begin{table}[H]
    \centering
    \begin{tabular}{l|l|l|l|l|}
        \textbf{Parameter} & \textbf{ground truth} & \textbf{m = 10} & \textbf{m = 100} & \textbf{m = 1000} \\
        \cline{1-5}

        smoker                 & 0.3   & 0.3757 & 0.3295 & 0.2923 \\
        pollution("low")       & 0.9   & 0.6944 & 0.9041 & 0.9148 \\
        pollution("high")      & 0.1   & 0.1000 & 0.0958 & 0.0851 \\
        p\_cancer\_0           & 0.03  & 0.0000 & 0.1110 & 0.0940 \\
        p\_cancer\_1           & 0.001 & 0.0000 & 0.0004 & 0.0254 \\
        p\_cancer\_2           & 0.05  & 0.0529 & 0.3773 & 0.7337 \\
        p\_cancer\_3           & 0.02  & 0.0726 & 0.1502 & 0.3007 \\
        p\_xray("positive")\_0 & 0.9   & 0.9581 & 0.8927 & 0.3741 \\
        p\_xray("negative")\_0 & 0.1   & 0.2550 & 0.1185 & 0.8205 \\
        p\_xray("positive")\_1 & 0.2   & 0.0000 & 0.1408 & 0.2268 \\
        p\_xray("negative")\_1 & 0.8   & 0.8571 & 0.8749 & 0.7738 \\
        p\_dyspnoea\_0         & 0.65  & 0.1533 & 0.0925 & 0.2314 \\
        p\_dyspnoea\_1         & 0.3   & 0.0000 & 0.3016 & 0.3302 \\

    \end{tabular}
\end{table}

\section{Observations for different number of interpretations}
For simpler parameters (the ones with fewer dependencies) like "smoker", "pollution(low)", "p\_dyspnoea\_1", etc., we notice that more interpretations causes the learned parameters to lie closer to the ground truth.

For more complex parameters (cancer and xray), however, the results are not as clear. There is no value for m that consistently performs better than the others for the more complex parameters.

We do note that the results listed above depend a lot on the random initialization of the EM algorithm. We would have had a better picture if we were able to restart the experiments many times and take averages, but as our implementation is quite slow, this wasn't feasible within the time frame for the project.