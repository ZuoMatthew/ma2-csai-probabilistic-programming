\section{PGM to CNF}

\subsection{ENC 1}
Our ENC1 encoding for the Cancer Bayesian network can be found in appendix~\ref{ENC1}. The CNF in dimacs format can be found under report/encodings/cancer/.

\subsection{ENC 2}
Our ENC2 encoding for the Cancer Bayesian network can be found in appendix~\ref{ENC2}. The CNF in dimacs format can be found under report/encodings/cancer/.



\section{SRL to CNF}
\subsection{Encoding of Monty Hall as CNF}
An encoding of problog programs can be generated by our program as follows:
\begin{lstlisting}
python3 scripts/inference.py --problog files/problog/monty_hall.pl
\end{lstlisting}
The CNF will be shown using the program's predicates. A version of the CNF in dimacs format will be shown as well.
See \texttt{README.MD} for more information.

Our CNF encoding for the given Monty Hall ProbLog program is:
\begin{align*}
    \land & (open\_door(2) \lor prize(2) \lor prize(3) \lor \neg p\_open\_door(2)\_0) \\
    \land & (open\_door(2) \lor prize(2) \lor \neg prize(3))                          \\
    \land & (\neg open\_door(2) \lor \neg prize(2) \lor \neg prize(2))                \\
    \land & (\neg open\_door(2) \lor \neg prize(2) \lor prize(3))                     \\
    \land & (\neg open\_door(2) \lor \neg prize(3) \lor \neg prize(2))                \\
    \land & (\neg open\_door(2) \lor \neg prize(3) \lor prize(3))                     \\
    \land & (\neg open\_door(2) \lor p\_open\_door(2)\_0 \lor \neg prize(2))          \\
    \land & (\neg open\_door(2) \lor p\_open\_door(2)\_0 \lor prize(3))               \\
    \land & (open\_door(3) \lor prize(2) \lor prize(3) \lor \neg p\_open\_door(3)\_0) \\
    \land & (open\_door(3) \lor prize(3) \lor \neg prize(2))                          \\
    \land & (\neg open\_door(3) \lor \neg prize(2) \lor \neg prize(3))                \\
    \land & (\neg open\_door(3) \lor \neg prize(2) \lor prize(2))                     \\
    \land & (\neg open\_door(3) \lor \neg prize(3) \lor \neg prize(3))                \\
    \land & (\neg open\_door(3) \lor \neg prize(3) \lor prize(2))                     \\
    \land & (\neg open\_door(3) \lor p\_open\_door(3)\_0 \lor \neg prize(3))          \\
    \land & (\neg open\_door(3) \lor p\_open\_door(3)\_0 \lor prize(2))               \\
    \land & (win\_keep \lor \neg prize(1))                                            \\
    \land & (\neg win\_keep \lor prize(1))                                            \\
    \land & (win\_switch \lor \neg prize(2) \lor open\_door(2))                       \\
    \land & (win\_switch \lor \neg prize(3) \lor open\_door(3))                       \\
    \land & (\neg win\_switch \lor prize(2) \lor prize(3))                            \\
    \land & (\neg win\_switch \lor prize(2) \lor \neg open\_door(3))                  \\
    \land & (\neg win\_switch \lor \neg open\_door(2) \lor prize(3))                  \\
    \land & (\neg win\_switch \lor \neg open\_door(2) \lor \neg open\_door(3))        \\
    \land & (\neg prize(1) \lor \neg prize(2))                                        \\
    \land & (\neg prize(1) \lor \neg prize(3))                                        \\
    \land & (\neg prize(2) \lor \neg prize(3))                                        \\
    \land & (prize(1) \lor prize(2) \lor prize(3))\\
    & \textbf{Weights:}             \\
    & W(p\_open\_door(2)\_0) = 0.5 & W &(\neg p\_open\_door(2)\_0) = 0.5 \\
    & W(p\_open\_door(3)\_0) = 0.5 & W &(\neg p\_open\_door(3)\_0) = 0.5 \\
    & W(select\_door(1)) = 1.00    & W &(\neg select\_door(1)) = 0.00    \\
    & W(prize(1)) = 0.33           & W &(\neg prize(1)) = 1.00           \\
    & W(prize(2)) = 0.33           & W &(\neg prize(2)) = 1.00           \\
    & W(prize(3)) = 0.33           & W &(\neg prize(3)) = 1.00           \\
    & W(open\_door(2)) = 1.00      & W &(\neg open\_door(2)) = 1.00      \\
    & W(open\_door(3)) = 1.00      & W &(\neg open\_door(3)) = 1.00      \\
    & W(win\_keep) = 1.00          & W &(\neg win\_keep) = 1.00          \\
    & W(win\_switch) = 1.00        & W &(\neg win\_switch) = 1.00        \\
\end{align*}


\section{Weighted Model Counting}
\subsection{Weighted model counters on above CNFs}
We have selected MiniC2D and Cachet as weighted model counters and have executed them on DIMACS versions of the CNFs of the previous tasks. The DIMACS files can be found under report/encodings.
The output of the model counters is listed below.

\subsubsection{MiniC2D}
MiniC2D needs to be executed with the $-W$ flag in order for it to do weighted model counting.
The resulting probability can be read next to ``Count''.

\begin{lstlisting}[caption={MiniC2D on ENC1 encoding of Cancer network}]
Constructing CNF... DONE
CNF stats:
  Vars=30 / Clauses=74
  CNF Time	0.000s
Constructing vtree (from primal graph)... DONE
Vtree stats:
  Vtree widths: con<=5, c_con=48 v_con=5
  Vtree Time	0.001s
Counting... DONE
  Learned clauses      	0
Cache stats:
  hit rate   	75.0%
  lookups    	16
  ent count  	4
  ent memory 	0.2 KB
  ht  memory 	152.6 MB
  clists     	1.0 ave, 1 max
  keys       	3.0b ave, 3.0b max, 3.0b min
Count stats:
  Count Time	0.000s
  Count 	0.9999999999999999
Total Time: 0.012s
\end{lstlisting}

\begin{lstlisting}[caption={MiniC2D on ENC2 encoding of Cancer network}]
Constructing CNF... DONE
CNF stats:
  Vars=20 / Clauses=30
  CNF Time	0.000s
Constructing vtree (from primal graph)... DONE
Vtree stats:
  Vtree widths: con<=6, c_con=16 v_con=6
  Vtree Time	0.000s
Counting... DONE
  Learned clauses      	0
Cache stats:
  hit rate   	23.1%
  lookups    	26
  ent count  	20
  ent memory 	1.0 KB
  ht  memory 	152.6 MB
  clists     	1.0 ave, 1 max
  keys       	1.8b ave, 3.0b max, 1.0b min
Count stats:
  Count Time	0.000s
  Count 	1.0000000000000000
Total Time: 0.012s
\end{lstlisting}

\begin{lstlisting}[caption={MiniC2D on CNF encoding of Monty Hall}]
Constructing CNF... DONE
CNF stats:
  Vars=10 / Clauses=26
  CNF Time	0.000s
Constructing vtree (from primal graph)... DONE
Vtree stats:
  Vtree widths: con<=4, c_con=22 v_con=4
  Vtree Time	0.000s
Counting... DONE
  Learned clauses      	0
Cache stats:
  hit rate   	20.0%
  lookups    	5
  ent count  	4
  ent memory 	0.2 KB
  ht  memory 	152.6 MB
  clists     	1.0 ave, 1 max
  keys       	3.2b ave, 4.0b max, 3.0b min
Count stats:
  Count Time	0.000s
  Count 	1.0000000000000000
Total Time: 0.011s
\end{lstlisting}

\subsubsection{Cachet}
For Cachet, there is no need to use extra parameters to get a probability.
It is reported next to ``Satisfying probability''.

\begin{lstlisting}[caption={Cachet on ENC1 encoding of Cancer network}]
Number of total components		11
Number of split components		2
Number of non-split components		5
Number of SAT residual formula		12
Number of trivial components		0
Number of changed components		0
Number of adjusted components		0
First component split level		1

Number of Decisions			11
Max Decision Level			5
Number of Variables			30
Original Num Clauses			74
Original Num Literals			172
Added Conflict Clauses			0
Added Conflict Literals			0
Deleted Unrelevant clauses		0
Deleted Unrelevant literals		0
Number of Implications			124
Total Run Time				0.0163

Satisfying probability			8.72319e-08
Number of solutions			93.6645

\end{lstlisting}

\begin{lstlisting}[caption={Cachet on ENC2 encoding of Cancer network}]
Number of total components		11
Number of split components		2
Number of non-split components		5
Number of SAT residual formula		12
Number of trivial components		0
Number of changed components		0
Number of adjusted components		0
First component split level		1

Number of Decisions			11
Max Decision Level			5
Number of Variables			20
Original Num Clauses			30
Original Num Literals			84
Added Conflict Clauses			0
Added Conflict Literals			0
Deleted Unrelevant clauses		0
Deleted Unrelevant literals		0
Number of Implications			72
Total Run Time				0.017372

Satisfying probability			1
Number of solutions			1.04858e+06

\end{lstlisting}

\begin{lstlisting}[caption={Cachet on WCNF encoding of Monty Hall}]
Number of total components		4
Number of split components		1
Number of non-split components		2
Number of SAT residual formula		5
Number of trivial components		0
Number of changed components		0
Number of adjusted components		0
First component split level		2

Number of Decisions			4
Max Decision Level			4
Number of Variables			10
Original Num Clauses			26
Original Num Literals			73
Added Conflict Clauses			0
Added Conflict Literals			0
Deleted Unrelevant clauses		0
Deleted Unrelevant literals		0
Number of Implications			26
Total Run Time				0.016062

Satisfying probability			0.444444
Number of solutions			455.111
\end{lstlisting}

For ENC1, we see that with Cachet reports a satisfying probability of almost 0. Similarly, for Monty Hall, we see that we get a probability of 0.44. This is due to the fact that with ENC1, the weights of negated literals are 1, but Cachet expects that $weight(x) + weight(-x) = 1$. In the Monty Hall encoding, we also have weights of negated literals equalling 1, which gives the same problem as with ENC1.

\subsection{Difference between the selected WMCs}
%The differences between the different WMCs come from \cite{CHAVIRA2008772}.
%\subsubsection{Cachet vs jointree and recursive conditioning}
%Jointree and recursive conditioning only exploit topological structure thus they take no advantage of the massive determinism available in networks whilst Cachet does this.

\subsubsection{MiniC2D Vs Cachet}
MiniC2D and Cachet are weighted model counters that work in different ways. In short, MiniC2D is a top down compiler that compiles CNFs into SDDs, while Cachet uses formula caching combined with clause learning and component analysis [\cite{MiniC2D},\cite{Cachet}].

Both weighted model counters use concepts from the SAT literature. They both use clause learning and component caching in order to reuse components that later appear again during search. \\
Cachet also uses other methods from SAT literature, like an explicit on the fly calculation of connected components. This is different in MiniC2D, as it relies on vtrees to identify disconnected CNF components. MiniC2d creates vtrees for CNFs and then creates SDDs based on the created vtrees.
%The way that the compilation is done with MiniC2D is as follows:
%The SDD compilation is driven by the vtree, it uses this to identify disconnected CNF components and it uses a component caching scheme to prevent compiling the same component multiple times.


\subsection{Overview of computational requirements}
We have executed the model counters with various CNFs to build an overview of computational requirements. The files we used for testing can be found under report/encodings. We have used scripts to convert the ``.dsc'' files to ENC1 and ENC2 encodings in DIMACS format. We downloaded the ``.dsc'' files from \url{http://www.bnlearn.com/bnrepository/}.

\subsubsection{Cancer network (small)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 0.3 KB    & 0.053s   & 1.0    & 1.0 KB    & 0.050s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.016s       & 1.0     & ?    & 0.016s    \\ \cline{1-7}
    \end{tabular}
\end{table}
% updated cancer with total time

\subsubsection{Asia network (small)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 1.2 KB    & 0.049s   & 1.0    & 1.9 KB    & 	 0.05s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.018s       & 1.0     & ?    & 0.017s    \\ \cline{1-7}
    \end{tabular}
\end{table}

\subsubsection{Sachs network (small)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 0.99707  & 16.8 KB    & 0.075s   & 1.0    & 13.4 KB   & 	0.07s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.019s       & 1.0     & ?    & 0.017s    \\ \cline{1-7}
    \end{tabular}
\end{table}
%sachs also updated

\subsubsection{Earthquake network (small)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 0.6 KB & 0.051s   & 1.0    & 1.0 KB  & 	0.05s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.016s       & 1.0     & ?    & 0.017s    \\ \cline{1-7}
    \end{tabular}
\end{table}

\subsubsection{Survey network (small)}
\begin{table}[H]
\centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 0.5 KB    & 0.035s   & 1.0    & 2.0 KB    & 	0.052s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.016s       & 1.0     & ?    & 0.016s    \\ \cline{1-7}
    \end{tabular}
\end{table}

\subsubsection{Alarm network (medium)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 0.999  & 451.1 KB    & 0.217s   & 0.999    & 143.4 KB    & 	0.093s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.176s       & 1.0     & ?    & 0.222s    \\ \cline{1-7}
\end{tabular}
\end{table}

\subsubsection{Child network (medium)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 45.8KB    & 0.076s   & 1.0    & 30.8 KB    & 	0.059s \\
      \hline
    \textbf{Cachet}  & 0.0  & ?    & 0.03s      & 1.0     & ?    & 0.03s    \\ \cline{1-7}
    \end{tabular}
\end{table}

\subsubsection{Hailfinder network (large)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 0.999  & 591.8 MB & 46.065s   & 1.0    & 25.1MB    & 	2.73s \\
      \hline
    \textbf{Cachet}  & 0  & ?    & 58.86s       & 1     & ?    & 15.21s    \\ \cline{1-7}
    \end{tabular}
\end{table}

\subsubsection{Andes network (very large)}
\begin{table}[H]
    \centering
    \begin{tabular}{c|c|c|c|c|c|c|}
    \cline{2-7}
            & \multicolumn{3}{c|}{ENC1} & \multicolumn{3}{c|}{ENC2} \\ \cline{2-7}
      & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} & \textbf{Prob}  & \textbf{Memory}  & \textbf{Runtime} \\ \cline{1-7}
      \textbf{Minic2d} & 1.0  & 5.5GB    & 266.605s   & 1.0    & 122.8 MB    & 	5.646s \\
      \hline
    \textbf{Cachet}  & ?  & ?    & $ > 4h (killed) $      & ?     & ?    & $ > 4h (killed) $     \\ \cline{1-7}
    \end{tabular}
\end{table}

For cachet we didn't find a way to output it's used memory so we'll have to leave this outside of the comparison.
From the results listed above, we can conclude that ENC2 is a better encoding than ENC1 as in most of the cases it is faster than the latter.
Concering the WMC's, we clearly see that Cachet is faster than minic2d when it comes to small to medium networks. Once we reach the large networks
and certainly the very large networks, Cachet is way slower than minic2d and for the very large networks Cachet couldn't even give a result
in 4 hours!

\section{Knowledge compilation}
\subsubsection{Vtree with the most compact circuit}
During our tests 
\subsubsection{Pattern for a good vtree}
As a vtree is a binary tree, which means that a good vtree is compact. We want thus a vtree that is shallow. 
